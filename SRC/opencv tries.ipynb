{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from imutils.object_detection import non_max_suppression\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import cv2\n",
    "import keras\n",
    "from Fun_to_prepare_data import * \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "def sliding_window(image, step, ws):\n",
    "    # slide a window across the image\n",
    "    for y in range(0, image.shape[0] - ws[1], step):\n",
    "        for x in range(0, image.shape[1] - ws[0], step):\n",
    "            # yield the current window\n",
    "            yield (x, y, image[y:y + ws[1], x:x + ws[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_pyramid(image, scale=1.2, minSize=(224, 224)):\n",
    "    # yield the original image\n",
    "    yield image\n",
    "    # keep looping over the image pyramid\n",
    "    while True:\n",
    "        # compute the dimensions of the next image in the pyramid\n",
    "        w = int(image.shape[1] / scale)\n",
    "        image = imutils.resize(image, width=w)\n",
    "        # if the resized image does not meet the supplied minimum\n",
    "        # size, then stop constructing the pyramid\n",
    "        if image.shape[0] < minSize[1] or image.shape[1] < minSize[0]:\n",
    "            break\n",
    "        # yield the next image in the pyramid\n",
    "        yield image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputs(imagen):\n",
    "    a=resize_image(imagen,(64,64))\n",
    "    a=np.asarray(a)\n",
    "    a= a.astype('float32') / 255\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 600\n",
    "PYR_SCALE = 1.5\n",
    "WIN_STEP = 5\n",
    "ROI_SIZE = (25,25)\n",
    "INPUT_SIZE = (64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('../weights/model_full_more_oranges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = cv2.imread(\"../../../../Desktop/screen_naranjo.png\")\n",
    "orig = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB)\n",
    "#orig = Image.open(\"../../../../Desktop/frutilla.jpg\")\n",
    "#orig = np.array(pic.getdata()).reshape(pic.size[0], pic.size[1], 3)\n",
    "orig = imutils.resize(orig, width=WIDTH)\n",
    "(H, W) = orig.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyramid = image_pyramid(orig, scale=PYR_SCALE, minSize=ROI_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] looping over pyramid/windows took 2.37719 seconds\n"
     ]
    }
   ],
   "source": [
    "rois = []\n",
    "locs = []\n",
    "start = time.time()\n",
    "for image in pyramid:\n",
    "    scale = W / float(image.shape[1])\n",
    "    c = sliding_window(image, WIN_STEP, ROI_SIZE)\n",
    "    for (x, y, roiOrig) in sliding_window(image, WIN_STEP, ROI_SIZE):\n",
    "        x = int(x * scale)\n",
    "        y = int(y * scale)\n",
    "        w = int(ROI_SIZE[0] * scale)\n",
    "        h = int(ROI_SIZE[1] * scale)\n",
    "        roi = cv2.resize(roiOrig, INPUT_SIZE)\n",
    "        roi = img_to_array(roi)\n",
    "        roi= roi.astype('float32') / 255\n",
    "        rois.append(roi)\n",
    "        locs.append((x, y, x + w, y + h))\n",
    "end = time.time()\n",
    "print(\"[INFO] looping over pyramid/windows took {:.5f} seconds\".format(\n",
    "    end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16829"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = np.array(rois, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] classifying ROIs...\n",
      "[INFO] classifying ROIs took 15.48619 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] classifying ROIs...\")\n",
    "start = time.time()\n",
    "preds = model.predict(rois)\n",
    "end = time.time()\n",
    "print(\"[INFO] classifying ROIs took {:.5f} seconds\".format(\n",
    "    end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41243663], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_bool= preds>=0.99\n",
    "np.sum(preds_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#predicciones=[]\n",
    "#for i in rois:\n",
    "#    print(i)\n",
    "#    predicciones.append(model.predict(np.expand_dims(i,axis=0))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#for i,x in enumerate(predicciones):\n",
    "#    print(i)\n",
    "#    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#max(preds)\n",
    "#preds.index(max(preds))\n",
    "#i, j = np.where(np.isclose(a, max(preds)))\n",
    "#i, = np.where(np.isclose(a, max(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#for i,x in enumerate(preds):\n",
    "#    print(i)\n",
    "#    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "naranjaid=\"naranja_id\"\n",
    "naranja_label=\"naranja\"\n",
    "preds_map=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,i in enumerate(preds):\n",
    "    preds_map.append((naranjaid,naranja_label,preds[x][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {}\n",
    "# loop over the predictions\n",
    "for (i, p) in enumerate(preds_map):\n",
    "    # grab the prediction information for the current ROI\n",
    "    (imagenetID, label, prob) = p\n",
    "    # filter out weak detections by ensuring the predicted probability\n",
    "    # is greater than the minimum probability\n",
    "    if prob >= 0.99:\n",
    "        # grab the bounding box associated with the prediction and\n",
    "        # convert the coordinates\n",
    "        box = locs[i]\n",
    "        # grab the list of predictions for the label and add the\n",
    "        # bounding box and probability to the list\n",
    "        L = labels.get(label, [])\n",
    "        L.append((box, prob))\n",
    "        labels[label] = L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'naranja'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] showing results for 'naranja'\n"
     ]
    }
   ],
   "source": [
    "# loop over the labels for each of detected objects in the image\n",
    "for label in labels.keys():\n",
    "    # clone the original image so that we can draw on it\n",
    "    print(\"[INFO] showing results for '{}'\".format(label))\n",
    "    clone = orig.copy()\n",
    "    # loop over all bounding boxes for the current label\n",
    "    for (box, prob) in labels[label]:\n",
    "        # draw the bounding box on the image\n",
    "        (startX, startY, endX, endY) = box\n",
    "        cv2.rectangle(clone, (startX, startY), (endX, endY),\n",
    "            (0, 255, 0), 2)\n",
    "    # show the results *before* applying non-maxima suppression, then\n",
    "    # clone the image again so we can display the results *after*\n",
    "    # applying non-maxima suppression\n",
    "cv2.imshow(\"Before\", clone)\n",
    "clone = orig.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the bounding boxes and associated prediction\n",
    "# probabilities, then apply non-maxima suppression\n",
    "boxes = np.array([p[0] for p in labels[label]])\n",
    "proba = np.array([p[1] for p in labels[label]])\n",
    "boxes = non_max_suppression(boxes, proba,overlapThresh=0)\n",
    "# loop over all bounding boxes that were kept after applying\n",
    "# non-maxima suppression\n",
    "for (startX, startY, endX, endY) in boxes:\n",
    "    # draw the bounding box and label on the image\n",
    "    cv2.rectangle(clone, (startX, startY), (endX, endY),(0, 255, 0), 2)\n",
    "    y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "    cv2.putText(clone, label, (startX, y),cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
    "    # show the output after apply non-maxima suppression\n",
    "\n",
    "cv2.imshow(\"After\", clone)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.pyimagesearch.com/2020/06/22/turning-any-cnn-image-classifier-into-an-object-detector-with-keras-tensorflow-and-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.pyimagesearch.com/2020/07/06/region-proposal-object-detection-with-opencv-keras-and-tensorflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.pyimagesearch.com/2020/07/06/region-proposal-object-detection-with-opencv-keras-and-tensorflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
